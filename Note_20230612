20230612
マッチングのアルゴリズムを調べてみる
ネットではword2vecなるもので作るらしい
（https://techblog.zozo.com/entry/clubzozo-algo）
過去の自分のonenoteとか見るとword2vecはNLP系なので
少しは基礎がある中でのスタートとなりそう

NLPはtokenizerで単語を小分けして
tfidfで頻出で順位付け
みたいな流れだった

https://qiita.com/yoppe/items/512c7c072d08c64afa7e#:~:text=%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6-,%EF%BC%92%E3%81%A4%E3%81%AE%E6%96%87%E7%AB%A0%E9%96%93,-%E3%81%AE%E5%B9%B3%E5%9D%87%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB
word2vecの類似度算出を使うらしい
2つの文章とあるが、どうやって「2つの文章」を定義しているのか不明
sentence_1、sentence_2は引数なので、どっかでそれは何になるかを指定してあげないといけないはず
↑
次元は「300」で指定しているが、sentence_1は指定してない

20230613
Mecabは単語ごとに区切る用途
私は東京にいる大学生です
⇒私は／東京に／いる／大学生です

これだとAさん、Bさんの趣味嗜好で共通項目が多い（類似度が高い）マッチングとなるが
それでいいのか？

20230615
word2vecで文章から類似度（コサイン類似度でベクトルの類似度を算出）とかは理解した。
csvとか色々なフォーマットでは、どうやって実行するのか？
重みづけとか、チューニング、学習データ蓄積ってどうやるの？
まずは色々なコードを回り道して吸収して、ある程度自分で仮説がつくれるようになってから
アルゴリズムを考える。
この自分の思想が、動き回れるようにするための学習期間がめっちゃしんどいが
これが血や肉になるのは理解しているのでやる。

類似度を算出できるってのは分かった
それから、どう人事マッチングに発展させる？
一般的に以下のコードで類似度を算出できるらしい
gensim
cosin_similarity
most_similar

CSVが対象でもできるのか？
⇒できる
　ただ結局、複数列を結合して文章にしている
　https://qiita.com/sanskruthiya/items/ac5b499f9eef3a183f9a

重みづけ、チューニングはどうやるのか？
⇒

学習データ


20230615
とりあえず、2人のマッチング度を簡単に算出するコード作ってみれば？
s3にデータ置くと面倒だから、メモリ上に一時的なデータセットでいいのでは？
⇒シンプルなコードは完成
　ただ、重みづけも何もない。全く同じ単語があればマッチという単純すぎる。

20230618
実はNLPでないのでは？と思い始めてる
NLPはトークン化して、次元削減して類似度を測定する
それは人事マッチングと違う気がする。
scikilearnの分類じゃないかと思い始めてる
パラメータ(専門、年齢、居住地)を数字にして分類する
この人は経理とか
でもそれって膨大な教師データが必要だよね。。。
当人にとってブラックな人との解消はどうするか？そこも考えないと。。。

20230619
メンバーと議論して、以下を「相性が良い」とした
・性格判断での相性が良いのを「相性が良い」とした
　https://mitsucari.com/blog/social_style_theory/
・自分と似ている人が「相性が良い」とはしない
　⇒そうなると、同じ年齢、出身地、家族構成と自分と同じ人が「相性が良い」となっていまう。






